# AI-NovelFlow

**[ç®€ä½“ä¸­æ–‡](README.md) | [ç¹é«”ä¸­æ–‡](README_TW.md) | [English](README_EN.md) | [æ—¥æœ¬èª](README_JA.md) | [í•œêµ­ì–´](README_KO.md)**

AI-Powered Novel to Video Platform

## Project Overview

NovelFlow is an AI platform that automatically converts novels into videos.

**Core Workflow:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Novel  â”‚ â†’ â”‚ AI Parse  â”‚ â†’ â”‚ Generate  â”‚ â†’ â”‚ Original  â”‚
â”‚         â”‚    â”‚ Charactersâ”‚    â”‚Character  â”‚    â”‚  Content  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Merge   â”‚ â† â”‚ Gen Transitionâ”‚ â† â”‚  Gen Shot     â”‚ â† â”‚   Gen Shot    â”‚
â”‚   Video   â”‚    â”‚    Video      â”‚    â”‚    Video      â”‚    â”‚     Image     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                    â†‘
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
                              â”‚ Merge Char    â”‚ â† â”‚  JSON     â”‚ â† â”˜
                              â”‚    Image      â”‚    â”‚ Structure â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Detailed Steps:**
1. **Novel** - Create new or import novel text
2. **AI Parse Characters** - Automatically extract character info (name, description, appearance)
3. **Generate Character Image** - Generate AI character portraits for each character
4. **Original Content** - Edit novel chapter content
5. **AI Split Shots** - Split chapters into shots (scene, camera, action)
6. **JSON Structure** - Generate shot data (characters, scenes, shot descriptions)
7. **Generate Merged Character Image** - Merge multiple characters into reference image (for shot generation)
8. **Generate Shot Images** - Generate scene images based on shot descriptions
9. **Generate Shot Videos** - Convert shot images into video clips
10. **Generate Transition Videos** - Generate transition videos between shots (optional)
11. **Merge Videos** - Combine all clips into a complete video

**Key Features:**
- Support for chapter-style novel parsing
- Character consistency (maintain character appearance across multiple scenes)
- Automatic shot generation and video composition

## Video Introduction

ğŸ“º <a href="https://www.bilibili.com/video/BV1VdZbBDEXF" target="_blank">Bilibili: AI-NovelFlow Novel to Video Platform Introduction</a>

ğŸ“º <a href="https://www.youtube.com/watch?v=IlMbeDme2F8" target="_blank">YouTube: AI-NovelFlow Novel to Video Platform Introduction</a>

## Tech Stack

- **Frontend**: React + TypeScript + Tailwind CSS + Vite
- **State Management**: Zustand (global state + i18n/timezone state)
- **Backend**: FastAPI + SQLAlchemy + SQLite
- **AI**: DeepSeek API / OpenAI API / Gemini API + ComfyUI
- **Video Generation**: LTX-2 video generation model
- **i18n**: Custom i18n implementation (5 languages supported)

## Main Features

- **Novel Management**: Support creating, editing, deleting novels, automatic chapter parsing
- **Character Library**: AI auto-parse characters, support character image generation and consistency
- **Shot Generation**: AI auto-split chapters into shots, support batch image and video generation
- **Transition Videos**: Support camera transitions, lighting transitions, occlusion transitions
- **Video Composition**: Support merging shot videos into complete chapter videos, auto-insert transitions
- **Workflow Management**: Support custom ComfyUI workflows, node mapping configuration
- **Task Queue**: Background async task processing, real-time task status monitoring
- **Preset Test Cases**: Built-in test cases like "The Little Horse Crosses the River", "Little Red Riding Hood", "The Emperor's New Clothes"
- **Multi-language Support**: Support Simplified Chinese, Traditional Chinese, English, Japanese, Korean interfaces
- **Timezone Support**: Users can customize timezone, all time displays are converted to specified timezone

## Project Structure

```
AI-NovelFlow/
â”œâ”€â”€ backend/              # FastAPI Backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/         # API Routes
â”‚   â”‚   â”œâ”€â”€ core/        # Core Configuration
â”‚   â”‚   â”œâ”€â”€ models/      # Database Models
â”‚   â”‚   â”œâ”€â”€ schemas/     # Pydantic Models
â”‚   â”‚   â””â”€â”€ services/    # Business Logic (LLM, ComfyUI)
â”‚   â”œâ”€â”€ user_story/      # Generated images/videos storage
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ frontend/            # React Frontend
â”‚   â””â”€â”€ my-app/
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ components/  # Components
â”‚       â”‚   â”œâ”€â”€ i18n/        # i18n translation files
â”‚       â”‚   â”œâ”€â”€ pages/       # Pages
â”‚       â”‚   â”œâ”€â”€ stores/      # State Management
â”‚       â”‚   â””â”€â”€ types/       # TypeScript Types
â”‚       â””â”€â”€ package.json
â”œâ”€â”€ windows_gpu_monitor/ # Windows GPU Monitor Service (Optional)
â”‚   â”œâ”€â”€ gpu_monitor.py   # GPU Monitor Service
â”‚   â”œâ”€â”€ requirements.txt # Dependencies
â”‚   â””â”€â”€ start.bat        # Windows Startup Script
â””â”€â”€ README.md
```

## Quick Start

### Backend Startup

```bash
cd backend
source venv/bin/activate  # Windows: venv\Scripts\activate
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

Backend service will run at http://localhost:8000

### Frontend Startup

```bash
cd frontend/my-app
npm install
npm run dev
```

Frontend service will run at http://localhost:5173

## API Documentation

Visit after starting backend: http://localhost:8000/docs

## Configuration

### 1. LLM API Configuration

Support multiple LLM providers:
- **DeepSeek** (default): https://api.deepseek.com
- **OpenAI**: https://api.openai.com
- **Gemini**: https://generativelanguage.googleapis.com
- **Anthropic**: https://api.anthropic.com
- **Azure OpenAI**: Custom Azure endpoint

Set API Key and proxy (if needed) in the [System Settings] page.

### 2. ComfyUI Configuration

- **ComfyUI Address**: Default http://localhost:8188
- **Workflow Configuration**: Support uploading custom workflows, need node mapping
  - Character Generation: Prompt node + Image save node
  - Shot Image: Prompt node + Image save node + Width/Height node
  - Shot Video: Prompt node + Video save node + Reference image node
  - Transition Video: First frame node + Last frame node + Video save node

#### 2.1 Model Files

Directory is based on `ComfyUI/models/...`; if you use ComfyUI-Manager, it generally scans these directories as well.

| Model Filename | Type | Main Purpose | Workflows Used | Recommended Directory |
|---------------|------|-------------|----------------|---------------------|
| `ltx-2-19b-dev-fp8.safetensors` | checkpoint / main model | LTX2 transition (occlusion/lighting/camera) video generation | LTX2 Occlusion Transition / Lighting Transition / Camera Transition | `models/checkpoints/` |
| `ltx-2-19b-distilled-fp8.safetensors` | checkpoint / main model | LTX2 video generation (direct/expanded) | LTX2 Video Generation - Direct / Expanded | `models/checkpoints/` |
| `gemma_3_12B_it_fp8_e4m3fn.safetensors` | text encoder (LTX text encoder) | LTX2 text encoding | All LTX2 workflows (transition/video generation) | `models/text_encoders/` |
| `ltx-2-19b-distilled-lora-384.safetensors` | LoRA | LTX2 distilled LoRA (enhance/match distillation process) | Mainly in transition workflows | `models/loras/` |
| `ltx-2-19b-lora-camera-control-dolly-left.safetensors` | LoRA | LTX2 camera control (dolly-left) | Mainly in transition workflows | `models/loras/` |
| `ltx-2-spatial-upscaler-x2-1.0.safetensors` | upscale model (latent upscaler) | LTX2 latent spatial upscale x2 | Mainly in transition workflows | `models/upscale_models/` |
| `ae.safetensors` | VAE / AE | Used as VAE/AE in Z-image-turbo and some default character workflows | Z-image-turbo Single Image / System Default - Character | `models/vae/` |
| `flux-2-klein-9b.safetensors` | UNet | Flux2-Klein shot image generation UNet | Flux2-Klein-9B Shot Image / System Default - Character | `models/unet/` |
| `flux2-vae.safetensors` | VAE | Flux2 VAE | Flux2-Klein-9B Shot Image / System Default - Character | `models/vae/` |
| `qwen_3_8b.safetensors` | text encoder | Flux2 text encoding | Flux2-Klein-9B Shot Image / System Default - Character | `models/clip/` |
| `z_image_turbo_bf16.safetensors` | UNet | Z-image-turbo single image generation UNet | Z-image-turbo Single Image / System Default - Character | `models/unet/` |
| `qwen_3_4b.safetensors` | text encoder | Z-image-turbo text encoding | Z-image-turbo Single Image / System Default - Character | `models/clip/` |

#### 2.2 Third-Party Node Packages

| Third-Party Node Package | GitHub Repository | Node class_type in Workflows |
|-------------------------|------------------|------------------------------|
| **LTXVideo / LTXV** | [Lightricks/ComfyUI-LTXVideo](https://github.com/Lightricks/ComfyUI-LTXVideo) | `LTXAVTextEncoderLoader`, `LTXVScheduler`, `LTXV*`, `LTXAV*`, `Painter*` |
| **VideoHelperSuite / VHS** | [Kosinkadink/ComfyUI-VideoHelperSuite](https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite) | `VHS_VideoCombine` |
| **Easy-Use** | [yolain/ComfyUI-Easy-Use](https://github.com/yolain/ComfyUI-Easy-Use) | `easy int`, `easy cleanGpuUsed`, `easy showAnything` |
| **LayerStyle / LayerUtility** | [chflame163/ComfyUI_LayerStyle](https://github.com/chflame163/ComfyUI_LayerStyle) | `LayerUtility: ImageScaleByAspectRatio V2` |
| **Comfyroll** | [Suzie1/ComfyUI_Comfyroll_CustomNodes](https://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes) | `CR Prompt Text`, `CR Text` |
| **FizzNodes / ConcatStringSingle** | [FizzleDorf/ComfyUI_FizzNodes](https://github.com/FizzleDorf/ComfyUI_FizzNodes) | `ConcatStringSingle` |
| **comfyui-various / JWInteger** | [jamesWalker55/comfyui-various](https://github.com/jamesWalker55/comfyui-various) | `JWInteger` |
| **ReservedVRAM** | [Windecay/ComfyUI-ReservedVRAM](https://github.com/Windecay/ComfyUI-ReservedVRAM) | `ReservedVRAMSetter` |
| **Qwen3-VL-Instruct / Qwen3_VQA** | [luvenisSapiens/ComfyUI_Qwen3-VL-Instruct](https://github.com/luvenisSapiens/ComfyUI_Qwen3-VL-Instruct) | `Qwen3_VQA` |

### 3. Windows GPU Monitor (Optional)

If ComfyUI runs on a remote Windows server, you can deploy the `windows_gpu_monitor` service to get real-time GPU status.

**Features**:
- Real-time monitoring of GPU usage, temperature, VRAM
- Monitor memory usage
- Display queue task count

**Deployment Steps**:

```bash
cd windows_gpu_monitor

# Install dependencies
pip install -r requirements.txt

# Start service
start.bat
```

Service runs at http://localhost:5000 by default

**Access Test**:
- Home: http://localhost:5000/
- GPU Status: http://localhost:5000/gpu-stats

### 4. Prompt Template Configuration

Support customization:
- AI parse characters system prompt
- Character generation prompt templates
- Chapter split prompt templates

### 5. Internationalization and Timezone Settings

**Language Settings**:
- Simplified Chinese (zh-CN)
- Traditional Chinese (zh-TW)
- English (en-US)
- æ—¥æœ¬èª (ja-JP)
- í•œêµ­ì–´ (ko-KR)

**Timezone Settings**:
- Support major global timezones
- All time displays (task list, LLM logs, etc.) converted to specified timezone
- Backend stores UTC time uniformly, frontend dynamically converts based on user settings

Configure in [System Settings] â†’ [Language & Timezone] page.

## Development Roadmap

- [x] Project Initialization
- [x] Basic Pages (Welcome, Config, Novel List)
- [x] Backend API Framework
- [x] DeepSeek API Integration (Text Parsing)
- [x] ComfyUI API Integration (Image/Video Generation)
- [x] Task Queue System
- [x] Character Library Management
- [x] Workflow Management System
- [x] JSON Parse Logs
- [x] Preset Test Cases
- [x] Multi-language Support (CN/EN/JP/KR/TW)
- [x] Timezone Support
- [x] Video Composition (support shot video merging, transition insertion)

## Usage Instructions

### 1. Create Novel
- Click [Create Novel] to create a novel
- Or select preset test cases for quick experience

### 2. AI Parse
- Click [AI Split Chapter] on the chapter page
- System automatically parses characters, scenes and shots

### 3. Generate Character Portraits
- Enter [Character Library] page
- Click [AI Generate All Character Images]

### 4. Generate Shot Images
- Enter [Chapter Generation] page
- Click [Generate All Shots]

### 5. Generate Shot Videos
- After shot images are generated
- Click [Generate All Shot Videos]

### 6. Generate Transition Videos (Optional)
- Generate transition videos between shots

## License

MIT
