# AI-NovelFlow

**[ç®€ä½“ä¸­æ–‡](README.md) | [ç¹é«”ä¸­æ–‡](README_TW.md) | [English](README_EN.md) | [æ—¥æœ¬èª](README_JA.md) | [í•œêµ­ì–´](README_KO.md)**

AI-Powered Novel to Video Platform

## Project Overview

NovelFlow is an AI platform that automatically converts novels into videos.

**Core Workflow:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Novel  â”‚ â†’ â”‚ AI Parse  â”‚ â†’ â”‚ AI Parse  â”‚ â†’ â”‚ Generate  â”‚ â†’ â”‚ Generate  â”‚
â”‚         â”‚    â”‚ Charactersâ”‚    â”‚  Scenes   â”‚    â”‚Character  â”‚    â”‚  Scene    â”‚
â”‚         â”‚    â”‚           â”‚    â”‚           â”‚    â”‚  Images   â”‚    â”‚  Images   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Merge   â”‚ â† â”‚ Gen Transitionâ”‚ â† â”‚  Gen Shot     â”‚ â† â”‚   Gen Shot    â”‚
â”‚   Video   â”‚    â”‚    Video      â”‚    â”‚    Video      â”‚    â”‚     Image     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                    â†‘
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
                              â”‚ Merge Char    â”‚ â† â”‚  JSON     â”‚ â† â”˜
                              â”‚    Image      â”‚    â”‚ Structure â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                              â†‘
                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
                                              â”‚   Edit    â”‚ â† â”˜
                                              â”‚  Chapter  â”‚
                                              â”‚AI Split   â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Detailed Steps:**
1. **Import Novel** - Create new or import novel text (TXT, EPUB supported)
2. **AI Parse Characters** - Automatically extract character info (name, description, appearance)
3. **AI Parse Scenes** - Automatically extract scene info (scene name, environment description)
4. **Generate Character Images** - Generate AI character portraits for each character
5. **Generate Scene Images** - Generate reference images for each scene (optional)
6. **Edit Chapter / AI Split Shots** - Edit chapter content, AI automatically splits into shots; supports incremental parsing of characters and scenes during editing
7. **JSON Structure** - Generate shot data (characters, scenes, shot descriptions)
8. **Generate Merged Character Image** - Merge multiple characters into reference image (for shot generation)
9. **Generate Shot Images** - Generate scene images based on shot descriptions
10. **Generate Shot Videos** - Convert shot images into video clips
11. **Generate Transition Videos** - Generate transition videos between shots (optional)
12. **Merge Videos** - Combine all clips into a complete video

**Key Features:**
- Support for chapter-style novel parsing
- Character consistency (maintain character appearance across multiple scenes)
- Scene consistency (maintain scene environment across multiple shots)
- Automatic shot generation and video composition

## Video Introduction

ğŸ“º <a href="https://www.bilibili.com/video/BV1VdZbBDEXF" target="_blank">Bilibili: AI-NovelFlow Novel to Video Platform Introduction</a>

ğŸ“º <a href="https://www.youtube.com/watch?v=IlMbeDme2F8" target="_blank">YouTube: AI-NovelFlow Novel to Video Platform Introduction</a>

ğŸ“º <a href="https://www.youtube.com/watch?v=DybveicQ9eQ" target="_blank">YouTube: How to Install on Windows</a>

## Community

| Telegram Group | QQ Group |
|:---:|:---:|
| <a href="https://t.me/AI_NovelFlow" target="_blank">@AI_NovelFlow</a> | 1083469624 |
| <img src="docs/telegram_group.png" width="200" alt="Telegram Group QR Code"> | <img src="docs/qq_group.png" width="200" alt="QQ Group QR Code"> |

## Tech Stack

- **Frontend**: React + TypeScript + Tailwind CSS + Vite
- **State Management**: Zustand (global state + i18n/timezone state)
- **Backend**: FastAPI + SQLAlchemy + SQLite
- **AI**: DeepSeek API / OpenAI API / Gemini API + ComfyUI
- **Video Generation**: LTX-2 video generation model
- **i18n**: Custom i18n implementation (5 languages supported)

## Main Features

- **Novel Management**: Support creating, editing, deleting novels, automatic chapter parsing
- **Character Library**: AI auto-parse characters, support character image generation and consistency
- **Scene Library**: AI auto-parse scenes, support scene reference image generation and environment settings
- **Shot Generation**: AI auto-split chapters into shots, support batch image and video generation
- **Transition Videos**: Support camera transitions, lighting transitions, occlusion transitions
- **Video Composition**: Support merging shot videos into complete chapter videos, auto-insert transitions
- **Workflow Management**: Support custom ComfyUI workflows, node mapping configuration
- **Task Queue**: Background async task processing, real-time task status monitoring
- **Preset Test Cases**: Built-in test cases like "The Little Horse Crosses the River", "Little Red Riding Hood", "The Emperor's New Clothes"
- **Multi-language Support**: Support Simplified Chinese, Traditional Chinese, English, Japanese, Korean interfaces
- **Timezone Support**: Users can customize timezone, all time displays are converted to specified timezone

## Project Structure

```
AI-NovelFlow/
â”œâ”€â”€ backend/              # FastAPI Backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/         # API Routes
â”‚   â”‚   â”œâ”€â”€ core/        # Core Configuration
â”‚   â”‚   â”œâ”€â”€ models/      # Database Models
â”‚   â”‚   â”œâ”€â”€ repositories/ # Data Repository Layer
â”‚   â”‚   â”œâ”€â”€ schemas/     # Pydantic Models
â”‚   â”‚   â”œâ”€â”€ services/    # Business Logic (LLM, ComfyUI)
â”‚   â”‚   â””â”€â”€ utils/       # Utility Functions
â”‚   â”œâ”€â”€ migrations/      # Database Migration Scripts
â”‚   â”œâ”€â”€ prompt_templates/ # Prompt Template Files
â”‚   â”œâ”€â”€ workflows/       # ComfyUI Workflow Configs
â”‚   â”œâ”€â”€ user_story/      # Generated images/videos storage
â”‚   â”œâ”€â”€ user_workflows/  # User Custom Workflows
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ frontend/            # React Frontend
â”‚   â””â”€â”€ my-app/
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ components/  # Components
â”‚       â”‚   â”œâ”€â”€ i18n/        # i18n translation files
â”‚       â”‚   â”œâ”€â”€ pages/       # Pages
â”‚       â”‚   â”œâ”€â”€ stores/      # State Management
â”‚       â”‚   â””â”€â”€ types/       # TypeScript Types
â”‚       â””â”€â”€ package.json
â”œâ”€â”€ windows_gpu_monitor/ # Windows GPU Monitor Service (Optional)
â”‚   â”œâ”€â”€ gpu_monitor.py   # GPU Monitor Service
â”‚   â”œâ”€â”€ requirements.txt # Dependencies
â”‚   â””â”€â”€ start.bat        # Windows Startup Script
â””â”€â”€ README.md
```

## Quick Start

### Backend Startup

```bash
cd backend
source venv/bin/activate  # Windows: venv\Scripts\activate
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

Backend service will run at http://localhost:8000

### Frontend Startup

```bash
cd frontend/my-app
npm install
npm run dev
```

Frontend service will run at http://localhost:5173

## API Documentation

Visit after starting backend: http://localhost:8000/docs

## Configuration

### 1. LLM API Configuration

Support multiple LLM providers:
- **DeepSeek** (default): https://api.deepseek.com
- **OpenAI**: https://api.openai.com
- **Gemini**: https://generativelanguage.googleapis.com
- **Anthropic**: https://api.anthropic.com
- **Azure OpenAI**: Custom Azure endpoint

Set API Key and proxy (if needed) in the [System Settings] page.

### 2. ComfyUI Configuration

- **ComfyUI Address**: Default http://localhost:8188
- **Workflow Configuration**: Support uploading custom workflows, need node mapping
  - Character Generation: Prompt node + Image save node
  - Scene Generation: Prompt node + Image save node + Width/Height node
  - Shot Image: Prompt node + Image save node + Width/Height node
  - Shot Video: Prompt node + Video save node + Reference image node
  - Transition Video: First frame node + Last frame node + Video save node

#### 2.1 Model Files

Directory is based on `ComfyUI/models/...`; if you use ComfyUI-Manager, it generally scans these directories as well.

| Model Filename | Type | Main Purpose | Workflows Used | Recommended Directory |
|---------------|------|-------------|----------------|---------------------|
| `ltx-2-19b-dev-fp8.safetensors` | checkpoint / main model | LTX2 transition (occlusion/lighting/camera) video generation | LTX2 Occlusion Transition / Lighting Transition / Camera Transition | `models/checkpoints/` |
| `ltx-2-19b-distilled-fp8.safetensors` | checkpoint / main model | LTX2 video generation (direct/expanded) | LTX2 Video Generation - Direct / Expanded | `models/checkpoints/` |
| `gemma_3_12B_it_fp8_e4m3fn.safetensors` | text encoder (LTX text encoder) | LTX2 text encoding | All LTX2 workflows (transition/video generation) | `models/text_encoders/` |
| `ltx-2-19b-distilled-lora-384.safetensors` | LoRA | LTX2 distilled LoRA (enhance/match distillation process) | Mainly in transition workflows | `models/loras/` |
| `ltx-2-19b-lora-camera-control-dolly-left.safetensors` | LoRA | LTX2 camera control (dolly-left) | Mainly in transition workflows | `models/loras/` |
| `ltx-2-spatial-upscaler-x2-1.0.safetensors` | upscale model (latent upscaler) | LTX2 latent spatial upscale x2 | Mainly in transition workflows | `models/upscale_models/` |
| `ae.safetensors` | VAE / AE | Used as VAE/AE in Z-image-turbo and some default character workflows | Z-image-turbo Single Image / System Default - Character | `models/vae/` |
| `flux-2-klein-9b.safetensors` | UNet | Flux2-Klein shot image generation UNet | Flux2-Klein-9B Shot Image / System Default - Character | `models/unet/` |
| `flux2-vae.safetensors` | VAE | Flux2 VAE | Flux2-Klein-9B Shot Image / System Default - Character | `models/vae/` |
| `qwen_3_8b.safetensors` | text encoder | Flux2 text encoding | Flux2-Klein-9B Shot Image / System Default - Character | `models/clip/` |
| `z_image_turbo_bf16.safetensors` | UNet | Z-image-turbo single image generation UNet | Z-image-turbo Single Image / System Default - Character | `models/unet/` |
| `qwen_3_4b.safetensors` | text encoder | Z-image-turbo text encoding | Z-image-turbo Single Image / System Default - Character | `models/clip/` |

#### 2.2 Third-Party Node Packages

| Third-Party Node Package | GitHub Repository | Node class_type in Workflows |
|-------------------------|------------------|------------------------------|
| **LTXVideo / LTXV** | [Lightricks/ComfyUI-LTXVideo](https://github.com/Lightricks/ComfyUI-LTXVideo) | `LTXAVTextEncoderLoader`, `LTXVScheduler`, `LTXV*`, `LTXAV*`, `Painter*` |
| **VideoHelperSuite / VHS** | [Kosinkadink/ComfyUI-VideoHelperSuite](https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite) | `VHS_VideoCombine` |
| **Easy-Use** | [yolain/ComfyUI-Easy-Use](https://github.com/yolain/ComfyUI-Easy-Use) | `easy int`, `easy cleanGpuUsed`, `easy showAnything` |
| **LayerStyle / LayerUtility** | [chflame163/ComfyUI_LayerStyle](https://github.com/chflame163/ComfyUI_LayerStyle) | `LayerUtility: ImageScaleByAspectRatio V2` |
| **Comfyroll** | [Suzie1/ComfyUI_Comfyroll_CustomNodes](https://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes) | `CR Prompt Text`, `CR Text` |
| **FizzNodes / ConcatStringSingle** | [FizzleDorf/ComfyUI_FizzNodes](https://github.com/FizzleDorf/ComfyUI_FizzNodes) | `ConcatStringSingle` |
| **comfyui-various / JWInteger** | [jamesWalker55/comfyui-various](https://github.com/jamesWalker55/comfyui-various) | `JWInteger` |
| **ReservedVRAM** | [Windecay/ComfyUI-ReservedVRAM](https://github.com/Windecay/ComfyUI-ReservedVRAM) | `ReservedVRAMSetter` |
| **Qwen3-VL-Instruct / Qwen3_VQA** | [luvenisSapiens/ComfyUI_Qwen3-VL-Instruct](https://github.com/luvenisSapiens/ComfyUI_Qwen3-VL-Instruct) | `Qwen3_VQA` |
| **Comfyui-zhenzhen** | [T8mars/Comfyui-zhenzhen](https://github.com/T8mars/Comfyui-zhenzhen) | `Zhenzhen_nano_banana`, `Zhenzhen API Settings` |

### 3. Windows GPU Monitor (Optional)

If ComfyUI runs on a remote Windows server, you can deploy the `windows_gpu_monitor` service to get real-time GPU status.

**Features**:
- Real-time monitoring of GPU usage, temperature, VRAM
- Monitor memory usage
- Display queue task count

**Deployment Steps**:

```bash
cd windows_gpu_monitor

# Install dependencies
pip install -r requirements.txt

# Start service
start.bat
```

Service runs at http://localhost:5000 by default

**Access Test**:
- Home: http://localhost:5000/
- GPU Status: http://localhost:5000/gpu-stats

### 4. Prompt Template Configuration

Support customization:
- AI parse characters system prompt
- Character generation prompt templates
- Chapter split prompt templates

### 5. Internationalization and Timezone Settings

**Language Settings**:
- Simplified Chinese (zh-CN)
- Traditional Chinese (zh-TW)
- English (en-US)
- æ—¥æœ¬èª (ja-JP)
- í•œêµ­ì–´ (ko-KR)

**Timezone Settings**:
- Support major global timezones
- All time displays (task list, LLM logs, etc.) converted to specified timezone
- Backend stores UTC time uniformly, frontend dynamically converts based on user settings

Configure in [System Settings] â†’ [Language & Timezone] page.

## Development Roadmap

- [x] Project Initialization
- [x] Basic Pages (Welcome, Config, Novel List)
- [x] Backend API Framework
- [x] DeepSeek API Integration (Text Parsing)
- [x] ComfyUI API Integration (Image/Video Generation)
- [x] Task Queue System
- [x] Character Library Management
- [x] Workflow Management System
- [x] JSON Parse Logs
- [x] Preset Test Cases
- [x] Multi-language Support (CN/EN/JP/KR/TW)
- [x] Timezone Support
- [x] Video Composition (support shot video merging, transition insertion)

## Usage Instructions

### 1. Create Novel
- Click [Create Novel] to create a novel
- Or select preset test cases for quick experience

### 2. AI Parse Characters and Scenes
- Click [AI Parse Characters] on novel detail page to extract character info
- Click [AI Parse Scenes] to extract scene info
- Support chapter range selection and incremental update

### 3. Generate Character and Scene Images
- Enter [Character Library] page, click [AI Generate All Character Images]
- Enter [Scene Library] page, click [Generate All Scene Images] (optional)

### 4. Edit Chapter and AI Split Shots
- Enter [Chapter Generation] page, click [AI Split Shots] to automatically split into shots
- Enter [Chapter Edit] page to edit chapter content, supports incremental parsing of characters and scenes during editing

### 5. Generate Shot Images
- Click [Generate All Shot Images]

### 6. Generate Shot Videos
- After shot images are generated
- Click [Generate All Shot Videos]

### 7. Generate Transition Videos (Optional)
- Generate transition videos between shots

### 8. Merge Video
- Click [Merge Video] to combine all clips into complete video

## License

MIT
